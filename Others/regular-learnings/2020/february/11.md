### Scalability
 - deploy
 - hosting service
 - VPS vs Webhost
 - Amazon EC2
 - Horizontal Scaling
   - buy more cheap
   - multiple server
   - distribute
     - load balancer
       - dns, round robin
       - client level cache
       - seperate server to serve seperate content(img, video, session)
       - Software LB
       - Hardware LB: ELB, HAProxy, 
       - active-active, active-passive
 - Vertical Scaling
   - add more cpu
   - more storage(sas, raid, sata, pata)
   - ram
   - constraints*
 - How to manage point of failure
   - if server goes down then how to handle the load
   - RAID
   - multiple server
   - replication
   - sticky session
 - Cache
   - file caching
   - db level
   - memcache
 - db
   - master slave
   - master master : heart beat
   - partitioning
 - High Availability
   - multiple building multiple server, insfrastructure


### Scalability for dummies
 - Clones
   - request are delivered to applications servers via load balancer for horizontal scaling. so those servers need to perform same operation. so need shared file, photos, session among them. we can use common data source for cache, external db or cache like memchache(faster). how to keep track codebase check - tools like capastrino
 - database
   - approach 1: hire dba, master-slave architecture, ram - ram - ram, sharding, denormalization, sql tuning
   - approach 2: start donormalization form the starting or use nosql db(easy to scale, ex: couchdb, mongodb) need cache
 - Cache
    - in memory cache, redis, memcached
    - pattern 1: cache db query
    - pattern 2: cache object
    - what to cache? session, object relationship, fully rendered blog, activity streams
 - async
    - scenario 1: preporcess the data and serve later, when the client request for data then he/she gets the cached data immediately
    - scenario 2: there is some specialized requirement, in this case we need to process the data after getting the request from the client so notify the client that some processing is going on and we'll notify you once done. 
    - use message broker like RabbitMQ, ActiveMQ, kafka etc. to handle async processing
    - if there is any heavy load processing thing then do it asynchronously. 

### System Design Premier basic concepts ( system design premier )
 - tradeoff
   - performance vs scalability
   - Latency vs throughput
   - Availability vs Consistency
     - CAP theorem
       - CP: if needs atomic operation
       - AP: if we need to return the recent available data, it might not be the latest data
 - Consistency Patterns : either get the latest data or error
   - synchronization   
   - types:
     - weak: after a while read may see or may not see, best approach is taken, ex: memcache, voip
     - eventual: eventually, ex: mail, dns
     - strong: data replicated synchronously, ex: rdbms
 - Availability patterns : 
   - two main patterns
     - fail - over
       - active-passive :  heartbit, downtime determine by passive is running or not
       - active-active : both server maintains traffic, spreading between them, application need to know, need public ip for both
     - replication
       - master-slave
       - master-master\
   - availability in numbers
 - DNS
   - maps domain to ip
   - cached by browser, os, router, isp, dns
   - ttl to expire
   - components:
     - NS
     - MX
     - record
     - cname
   - cloudfront, route 53 provide managed dns service
   - weighted round robin, geolocation, latency
   - disadvantage: latency, setup complex, ddos
 - CDN 
   - globally distributed proxy server, serve content location closer to the user
   - two main facility: faster, server don't need to handle the serve request
   - types
     - push cdn : server need to push the change to the cdn
     - pull cdn : cdn cache the data when user request first, ttl determines when to pull
 - Load Balancer
   - application servers, database
   - request distribute based on:
     - header
     - sticky session
     - least busy
     - round robin
     - randomly
   - can also perform:
     - certificate verification
     - encryption
     - session persistence
   - level 4 : transport layer, ip, port to decide where to send, NAT
   - level 7 : application layer, header, message, cookie to decide. ex: to get video data request can be redirected to video server
 - Horizontal Scaling
   - disadvantage: 
     - introduce complexity
     - need common session for all servers as they should be stateless  
 - Reverse Proxy
   - centralizes internal services and give unfied interface to the public
   - benefits:
     - ssl termination
     - compression
     - static contents
     - increase scalability and flexibility
     - caching
   - Load balancer vs Proxy
 - Application Layer
   - seperating applicaiton/ platform layer from the web layer gives us the facility to scale/flexibility
   - new api add means adding new application server and it's not necessary to add new web server
   - service based architecture - single responsiblity
   - workers give the facility for async
 - Microservice Architecture
   - suite of independently deployable, modular, small services
   - ex: pinterest has this acrh. profile, serach, photo upload, feed, follower etc. 
 - Service Discovery
   - help services by keeping info.
   - ex: zookeeper
 - Database
   - RDBMS
     - ACID properties in transaction
     - scale
       - master-slave
       - master-master
         - write to application logic that where to write
         - loosley consistent(violate ACID) or creates lag for synchronization
         - more slave more lag
         - more hardware and complexity
       - Federation
         - split db by functionality
         - instead of single database we can have multiple database 
       - Sharding
         - distribute data to multiple database servers where each database can manage set of data
         - consistent hashing
       - Denormalization
       - SQL tuning
         - by benchmarking/load testing & profiling we can get bottlenecks
           - use data type efficiently
           - good indices
           - denormalization
           - partition
           - cache
   - NoSQL
     - types
       - key-value : hashtable
         - O(1) read/write, backend by ssd
         - in-memory cache layer
       - document-storage : key-value where value is document
         - mainly json, xml, binary data centred
         - dynamodb support both key-value, document-storage   
         - mongo/couch
       - wide-column : nested map
         - google's big table, (hbase, hadoop), cassandra
       - graph
         - node, edge
         - neo4js
     - BASE
       - basic availability, soft state, eventual consistency
   - SQL or NoSQL
     - SQL
       - structured data
       - relational data
       - join
       - indexing
       - transaction
       - strict schema
     - NonSQL
       - semi structured data
       - dynamic data
       - non-relational data
       - highscalable 
       - no need of complex join
 - Cache
   - client caching
   - cdn caching
   - web server caching
   - database caching
   - os caching
   - application caching
     - memcached or redis
   - cache update policy
     - cache-aside : basic
     - write through
       - read and write to the cache and then the cache will be responsible for reading and writing to db
     - write behind
       - write to cache and async write entry to db
     - refresh ahead
       - refreash when expire
 - Asynchronism
   - helps to reduce time for expensive operation that would be performed in-line
   - Message Queues
     - receive, holds and delivers message
     - redis, rabbitmq, amazon sqs
   - Task Queue
   - Back Pressure
 - Communication
   - OSI
     - A : SMTP
     - P : pdf, jpeg, 
     - S : session, security, logging
     - T : tcp, udp
     - N : packet
     - D : frame
     - P : physical structure
   - HTTP
     - application layer protocol need tcp /udp , request-response, transport data between client & server

   - TCP
     - connection oriented protocol over ip
     - packets sent and guaranteed to reach the destination
       - sync
       - ack
     - flow control, congestion control
     - used where high reliablity but less time critical
     - when data need intact
   - UDP
     - connectionless, datagram 
     - dhcp
     - voip, video streaming, gaming
     - used where low latency needed than loss of data
   - RPC
     - client call procedure to execute in different address space usually in remote server
     - components
       - client program
       - client stub
       - client communication module
       - server communication module
       - server stub
   - REST
     - architectural style, client-server model where client act on set of resources managed by server
     - all communication stateless and cacheable
     - 4 qualities
       - uri
       - verb
       - response/status code
       - browser accesible
     - good for horizontal scaling
 - Security
   - encryption, sql injection, xss, least privilege

### System Design Basics (grokking)
 - some tools
   - dynamo, kafka, consistent hashing, zookeeper, map reducer, hadoop
   - *paxos, *concurrency control, *gossip protocol, *chubby
 - Key Characteristics of Distributed System
   - Scalability
     - horizontal, vertical
   - Reliablity
     - probability of failing within a given time
   - Avaialability
     - availability vs reliability
   - Efficiency
     - latency, throughput
   - Managability
 - Load Balancing
   - Load Balancing Algorithm
     - health check continuously and if any server not responding then reroute request
     - least connection method
     - least bandwidth
     - round robin
     - weighted round robin
     - ip hash
   - redundant load balancer
 - Caching
   - application layer cache
     - each application can have their own cache but  as lb redirect request to different server so cache miss can happen
       - CDN
       - Cache invalidation
         - write thorough
         - write around
         - write back
       - cache eviction policies
         - FIFO, LIFO, LRU, MRU, RR, LFU
 - Sharding and Data Partitioning
   - Partitioning
     - Horizontal : sharding
     - Vertical : federation
     - Directory Based : resolves issue of the previous two scheme
   - Partitioning Criteria
     - hash based
     - round robin
     - list based
       - by location
     - composite hashing
       - consistent hashing : composite of hash and list
   - Common Problem of Sharding
     - join and denormalization
     - referential integrity
     - rebalancing: data distribution is not uniform
   - Indexing
     - purpose of adding index is to increase the performance of search queries
     - but, adding, removing, updating data need to update the index which will make the db slower, so need to be careful about indexing
   - Proxies
     - filter requet, log request, transform header/encrypt/decrypt, cache
     - types of proxy
       - open proxy
         - anonymous
         - transparent
       - reverse proxy
   - Redundancy and replication
 - SQL vs NoSQL
   - storage mechanism
   - schema
   - query language
     - sql, unsql
   - scaling
   - transaction
 - which one to use?
   - no one-size-fits-all
- CAP
- Consistent Hashing
  - objects map to same host if possible
  - if host removed then that host is shared by another, when new added then it shares from a few hosts without touching other
  - how it works?
    - let output of a hash function [0, 256) in a circular manner
    - suppose a chache server added and hash it 
    - to map a key, hash it and go clockwise until finiding server
    - the server might be unbalanced and to solve the issue a server is mapped multiple point on the ring
- Long Polling vs WebSockets vs Server Sent Events
  - ajax polling
  - long polling
  - websocket
  - server sent events

### System Design
#### Design webservice that scales in AWS
- Collect all the reuirements, specify use case, constraints, assumptions and collct necessary information
- 1. start with single machine EC2, db in same machine. stop outbound connection except port 80,443, 22 for security purpose
- 2. with continuous benchmarking, load testing & profiling we can find that disk space are filling and space running out, db is getting filled, so we can shift db to separate machine and static content to separate machine - amazon s3 to lighten application server
- 3. by monitoring find out that, need vertical scaling, load balancer(HAProxy, ELB), separate webserver and application server
- 4. mysql becomes slower, introduce master slave architecture
- 5. introduce autoscaling, automate deops
- 6. introduce cache, as need to server 40k read request 
- 7. simply single mysql machine can't handle too many requests like this amount so need to introduce some mysql scaling pattern(federation, sharding, sql tuning, denormalization). we can also do some async processing/ batch operation to make certain task faster.
